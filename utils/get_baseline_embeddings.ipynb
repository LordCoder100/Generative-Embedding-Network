{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da5b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp310-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 73.6 MB 187 kB/s eta 0:00:013\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp310-cp310-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.4 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai\n",
      "  Downloading openai-1.107.2-py3-none-any.whl (946 kB)\n",
      "\u001b[K     |████████████████████████████████| 946 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 261 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.3.0-cp310-cp310-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 989 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.59.2-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (322 kB)\n",
      "\u001b[K     |████████████████████████████████| 322 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "\u001b[K     |████████████████████████████████| 444 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 3.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting idna>=2.8\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: sniffio, idna, h11, certifi, typing-inspection, pydantic-core, numpy, mpmath, MarkupSafe, httpcore, anyio, annotated-types, tqdm, threadpoolctl, sympy, scipy, pyparsing, pydantic, pillow, networkx, kiwisolver, joblib, jiter, jinja2, httpx, fsspec, fonttools, filelock, distro, cycler, contourpy, torch, scikit-learn, openai, matplotlib\n",
      "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 contourpy-1.3.2 cycler-0.12.1 distro-1.9.0 filelock-3.19.1 fonttools-4.59.2 fsspec-2025.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jinja2-3.1.6 jiter-0.10.0 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 openai-1.107.2 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyparsing-3.2.4 scikit-learn-1.7.2 scipy-1.15.3 sniffio-1.3.1 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.8.0 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch matplotlib scikit-learn numpy scipy openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1060fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (4.67.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce593a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка токенів: 100%|██████████| 563/563 [01:25<00:00,  6.60tok/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Додано 184 нових токенів. Загалом: 5090\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from openai import OpenAI \n",
    "import pandas as pd \n",
    "from tqdm import tqdm as tqdm \n",
    "\n",
    "class Baseline:\n",
    "    def __init__(self, openai_client: OpenAI) -> None:\n",
    "        self.openai_client = openai_client\n",
    "\n",
    "    def get_embedding(self, source_text: str, model_name: str = \"text-embedding-3-small\"):\n",
    "        source_text = source_text.replace(\"\\n\", \" \")\n",
    "        return self.openai_client.embeddings.create(\n",
    "            input=[source_text],\n",
    "            model=model_name\n",
    "        ).data[0].embedding\n",
    "    \n",
    "\n",
    "def main() -> None:\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    output_path = \"output/token_embeddings.csv\"\n",
    "\n",
    "    client = OpenAI(api_key=os.environ.get(\"API_KEY\"))\n",
    "    controller = Baseline(openai_client=client)\n",
    "\n",
    "    text = \"\"\"\n",
    "    Meta said it will introduce more guardrails to its artificial intelligence (AI) chatbots - including blocking them from talking to teens about suicide, self-harm and eating disorders.\n",
    "    It comes two weeks after a US senator launched an investigation into the tech giant after notes in a leaked internal document suggested its AI products could have \"sensual\" chats with teenagers.\n",
    "    The company described the notes in the document, obtained by Reuters, as erroneous and inconsistent with its policies which prohibit any content sexualising children.\n",
    "    But it now says it will make its chatbots direct teens to expert resources rather than engage with them on sensitive topics such as suicide.\n",
    "    \"We built protections for teens into our AI products from the start, including designing them to respond safely to prompts about self-harm, suicide, and disordered eating,\" a Meta spokesperson said.\n",
    "    The firm told tech news publication TechCrunch on Friday it would add more guardrails to its systems \"as an extra precaution\" and temporarily limit chatbots teens could interact with.\n",
    "    But Andy Burrows, head of the Molly Rose Foundation, said it was \"astounding\" Meta had made chatbots available that could potentially place young people at risk of harm.\n",
    "    \"While further safety measures are welcome, robust safety testing should take place before products are put on the market - not retrospectively when harm has taken place,\" he said.\n",
    "    \"Meta must act quickly and decisively to implement stronger safety measures for AI chatbots and Ofcom should stand ready to investigate if these updates fail to keep children safe.\"\n",
    "    Meta said the updates to its AI systems are in progress. It already places users aged 13 to 18 into \"teen accounts\" on Facebook, Instagram and Messenger, with content and privacy settings which aim to give them a safer experience.\n",
    "    It told the BBC in April these would also allow parents and guardians to see which AI chatbots their teen had spoken to in the last seven days.\n",
    "    Safety concerns\n",
    "    The changes come amid concerns over the potential for AI chatbots to mislead young or vulnerable users.\n",
    "    A California couple recently sued ChatGPT-maker OpenAI over the death of their teenage son, alleging its chatbot encouraged him to take his own life.\n",
    "    The lawsuit came after the company announced changes to promote healthier ChatGPT use last month.\n",
    "    \"AI can feel more responsive and personal than prior technologies, especially for vulnerable individuals experiencing mental or emotional distress,\" the firm said in a blog post.\n",
    "    Meanwhile, Reuters reported on Friday Meta's AI tools allowing users to create chatbots had been used by some - including a Meta employee - to produce flirtatious \"parody\" chatbots of female celebrities.\n",
    "    Among celebrity chatbots seen by the news agency were some using the likeness of artist Taylor Swift and actress Scarlett Johansson.\n",
    "    Reuters said the avatars \"often insisted they were the real actors and artists\" and \"routinely made sexual advances\" during its weeks of testing them.\n",
    "    It said Meta's tools also permitted the creation of chatbots impersonating child celebrities and, in one case, generated a photorealistic, shirtless image of one young male star.\n",
    "    Several of the chatbots in question were later removed by Meta, it reported.\n",
    "    \"Like others, we permit the generation of images containing public figures, but our policies are intended to prohibit nude, intimate or sexually suggestive imagery,\" a Meta spokesperson said.\n",
    "    They added that its AI Studio rules forbid \"direct impersonation of public figures\".\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        df_existing = pd.read_csv(output_path)\n",
    "        existing_tokens = set(df_existing[\"token\"].tolist())\n",
    "    else:\n",
    "        df_existing = pd.DataFrame(columns=[\"token\", \"embedding\"])\n",
    "        existing_tokens = set()\n",
    "\n",
    "    new_rows = []\n",
    "    for tok in tqdm(tokens, desc=\"Обробка токенів\", unit=\"tok\"):\n",
    "        if tok not in existing_tokens:\n",
    "            emb = controller.get_embedding(tok)\n",
    "            new_rows.append({\"token\": tok, \"embedding\": emb})\n",
    "\n",
    "    if new_rows:\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        df_all = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_all.to_csv(output_path, index=False)\n",
    "        print(f\"Додано {len(new_rows)} нових токенів. Загалом: {len(df_all)}\")\n",
    "    else:\n",
    "        print(\"Нових токенів немає — все вже в CSV.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7610fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pillow in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from tensorboard) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from tensorboard) (2.2.6)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "\u001b[K     |████████████████████████████████| 426 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from tensorboard) (58.1.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from tensorboard) (25.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-macosx_11_0_universal2.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.3.1 grpcio-1.74.0 markdown-3.9 protobuf-6.32.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cffb55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/mykhailolapshyn/Desktop/Generative Embedding Network/.venv/lib/python3.10/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-25.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9435d",
   "metadata": {},
   "source": [
    "**NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|███████████████████████████████████████████| 1018/1018 [16:04<00:00,  1.06it/s, loss=0.0097, cos=0.9903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2 - TrainLoss: 0.0456, ValLoss: 0.0089, TrainCos: 0.9544, ValCos: 0.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|███████████████████████████████████████████| 1018/1018 [15:00<00:00,  1.13it/s, loss=0.0045, cos=0.9955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/2 - TrainLoss: 0.0081, ValLoss: 0.0045, TrainCos: 0.9919, ValCos: 0.9955\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Dataset\n",
    "# ==========================\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, tokens, embeddings) -> None:\n",
    "        super().__init__()\n",
    "        self.tokens = tokens\n",
    "        self.embeddings = torch.tensor(np.array(embeddings), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokens[idx], self.embeddings[idx]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Blocks\n",
    "# ==========================\n",
    "class BilinearGLUBlock(nn.Module):\n",
    "    def __init__(self, dim: int, drop: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.bilinear = nn.Bilinear(dim, dim, dim)\n",
    "        self.glu = nn.GLU(dim=-1)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.bilinear(\n",
    "            x.to(self.bilinear.weight.dtype), \n",
    "            x.to(self.bilinear.weight.dtype)\n",
    "        )\n",
    "        h = self.glu(torch.cat([h, h], dim=-1))\n",
    "        h = self.drop(h)\n",
    "        return self.norm(h + x.to(h.dtype))\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Encoders\n",
    "# ==========================\n",
    "class ForwardEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.block = BilinearGLUBlock(hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = F.silu(self.fc(x))\n",
    "        return self.block(h)\n",
    "\n",
    "\n",
    "class BackwardEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.block = BilinearGLUBlock(hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = torch.flip(x, dims=[0])\n",
    "        h = F.silu(self.fc(h))\n",
    "        return self.block(h)\n",
    "\n",
    "\n",
    "class BidirectionalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int = 1536, hidden_dim: int = 512, out_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.forward_encoder = ForwardEncoder(input_dim, hidden_dim)\n",
    "        self.backward_encoder = BackwardEncoder(input_dim, hidden_dim)\n",
    "        self.combine = nn.Linear(hidden_dim * 2, out_dim)\n",
    "        self.norm = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        fwd = self.forward_encoder(x)\n",
    "        bwd = self.backward_encoder(x)\n",
    "        combined = torch.cat([fwd, bwd], dim=-1)\n",
    "        out = self.combine(combined)\n",
    "        return self.norm(out)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Model\n",
    "# ==========================\n",
    "class LinguaGEN(nn.Module):\n",
    "    def __init__(self, input_dim=1536, hidden_dim=512, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = BidirectionalEncoder(input_dim, hidden_dim, out_dim)\n",
    "        self.projection_head = ProjectionHead(out_dim, hidden_dim, out_dim)\n",
    "        self.baseline_proj = nn.Linear(input_dim, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pred = self.encoder(x)\n",
    "        pred = self.projection_head(pred)\n",
    "        pred = F.normalize(pred, dim=-1)\n",
    "\n",
    "        baseline = self.baseline_proj(x)\n",
    "        baseline = F.normalize(baseline, dim=-1)\n",
    "\n",
    "        return pred, baseline\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Loss\n",
    "# ==========================\n",
    "class CosineSimilarityContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        cos_sim = F.cosine_similarity(pred, target, dim=-1)\n",
    "        loss = 1 - cos_sim.mean()\n",
    "        return loss, cos_sim.mean()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Training\n",
    "# ==========================\n",
    "# ==========================\n",
    "# Training\n",
    "# ==========================\n",
    "def split_dataset(tokens, embeddings, batch_size=4):\n",
    "    dataset = EmbeddingDataset(tokens, embeddings)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=2, lr=1e-4, accumulation_steps=4):\n",
    "    criterion = CosineSimilarityContrastiveLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_cos = -1.0\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        train_loss, train_cos = 0, 0\n",
    "\n",
    "        batch_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", ncols=120)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for step, (_, embeddings) in enumerate(batch_bar):\n",
    "            embeddings = embeddings.to(device)\n",
    "\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float32):\n",
    "                pred, baseline = model(embeddings)\n",
    "                loss, cos_sim = criterion(pred, baseline)\n",
    "                loss = loss / accumulation_steps  \n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                if device.type == \"cuda\":\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item() * accumulation_steps\n",
    "            train_cos += cos_sim.item()\n",
    "\n",
    "            if step % 10 == 0:  \n",
    "                batch_bar.set_postfix({\n",
    "                    \"loss\": f\"{loss.item() * accumulation_steps:.4f}\",\n",
    "                    \"cos\": f\"{cos_sim.item():.4f}\"\n",
    "                })\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss, val_cos = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for _, embeddings in val_loader:\n",
    "                embeddings = embeddings.to(device)\n",
    "                with torch.autocast(device_type=device.type, dtype=torch.float16 if device.type != \"cpu\" else torch.bfloat16):\n",
    "                    pred, baseline = model(embeddings)\n",
    "                    loss, cos_sim = criterion(pred, baseline)\n",
    "                val_loss += loss.item()\n",
    "                val_cos += cos_sim.item()\n",
    "\n",
    "        # ---- Averages ----\n",
    "        train_loss /= len(train_loader)\n",
    "        train_cos /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_cos /= len(val_loader)\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "        # ---- Logs ----\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"CosSim/Train\", train_cos, epoch)\n",
    "        writer.add_scalar(\"CosSim/Val\", val_cos, epoch)\n",
    "\n",
    "        # ---- Save checkpoints ----\n",
    "        ckpt_path = f\"checkpoints/epoch_{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "        if val_cos > best_val_cos:\n",
    "            best_val_cos = val_cos\n",
    "            torch.save(model.state_dict(), \"checkpoints/best_model.pth\")\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} \"\n",
    "              f\"- TrainLoss: {train_loss:.4f}, ValLoss: {val_loss:.4f}, \"\n",
    "              f\"TrainCos: {train_cos:.4f}, ValCos: {val_cos:.4f}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \n",
    "    data = pd.read_csv(\"/Users/mykhailolapshyn/Desktop/Generative Embedding Network/utils/output/token_embeddings.csv\")\n",
    "\n",
    "    tokens = data[\"token\"].to_list()\n",
    "   \n",
    "    embeddings = [ast.literal_eval(e) for e in data[\"embedding\"].to_list()]\n",
    "\n",
    "    train_dataloader, val_dataloader = split_dataset(tokens, embeddings)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = LinguaGEN()\n",
    "    epochs = 2\n",
    "    lr = 1e-4\n",
    "    train_model(model=model,\n",
    "                train_loader=train_dataloader,\n",
    "                val_loader=val_dataloader,\n",
    "                device=device,\n",
    "                epochs=epochs,\n",
    "                lr=lr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings('ignore')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0a1c4",
   "metadata": {},
   "source": [
    "**INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Ukraine and Japan: 0.9987\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import ast \n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"API_KEY\"))\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = LinguaGEN()\n",
    "model.load_state_dict(torch.load(\n",
    "    \"/Users/mykhailolapshyn/Desktop/Generative Embedding Network/utils/checkpoints/epoch_2.pth\",\n",
    "    map_location=device\n",
    "))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "df = pd.read_csv(\"/Users/mykhailolapshyn/Desktop/Generative Embedding Network/utils/output/token_embeddings.csv\")\n",
    "\n",
    "def get_embedding_from_csv(word, df):\n",
    "    row = df[df[\"token\"] == word]\n",
    "    if len(row) == 0:\n",
    "        return None\n",
    "    emb = np.array(ast.literal_eval(row[\"embedding\"].values[0]), dtype=np.float32)\n",
    "    return torch.tensor(emb, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def get_embedding_openai(word):\n",
    "    resp = client.embeddings.create(model=\"text-embedding-3-small\", input=word)\n",
    "    emb = np.array(resp.data[0].embedding, dtype=np.float32)\n",
    "    return torch.tensor(emb, dtype=torch.float32)\n",
    "\n",
    "# =========================\n",
    "# Comparison Ukraine vs Japan\n",
    "# =========================\n",
    "word1 = \"Ukraine\"\n",
    "word2 = \"Japan\"\n",
    "\n",
    "emb1 = get_embedding_from_csv(word1, df)\n",
    "if emb1 is None:\n",
    "    emb1 = get_embedding_openai(word1)\n",
    "emb1 = emb1.unsqueeze(0).to(device)\n",
    "\n",
    "# Для Japan беремо з CSV\n",
    "emb2 = get_embedding_from_csv(word2, df)\n",
    "if emb2 is None:\n",
    "    emb2 = get_embedding_openai(word2)\n",
    "emb2 = emb2.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen1 = model(emb1)[0]\n",
    "    gen2 = model(emb2)[0]\n",
    "\n",
    "cos = torch.nn.functional.cosine_similarity(gen1, gen2).item()\n",
    "print(f\"Cosine Similarity between {word1} and {word2}: {cos:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120adb3d",
   "metadata": {},
   "source": [
    "**FINISH** :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71171b32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc93b89",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
